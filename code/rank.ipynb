{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: 导入依赖和初始设置\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "from utils import Logger, evaluate, gen_sub\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "seed = 2020\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-19 19:35:56,518 - /tmp/ipykernel_978832/3530196446.py[line:5] - INFO: lightgbm 排序，mode: valid\n",
      "2025-04-19 19:35:56,518 - /tmp/ipykernel_978832/3530196446.py[line:5] - INFO: lightgbm 排序，mode: valid\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: 参数配置和日志记录\n",
    "mode = 'valid'  # 'valid' or 'online'\n",
    "os.makedirs('../user_data/log', exist_ok=True)\n",
    "log = Logger('../user_data/log/notebook.log').logger\n",
    "log.info(f'lightgbm 排序，mode: {mode}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: 定义模型训练函数\n",
    "def train_model(df_feature, df_query):\n",
    "    df_train = df_feature[df_feature['label'].notnull()]\n",
    "    df_test = df_feature[df_feature['label'].isnull()]\n",
    "    \n",
    "    del df_feature\n",
    "    gc.collect()\n",
    "    \n",
    "    ycol = 'label'\n",
    "    feature_names = list(filter(lambda x: x not in [ycol, 'created_at_datetime', 'click_datetime'], df_train.columns))\n",
    "    feature_names.sort()\n",
    "    \n",
    "    model = lgb.LGBMClassifier(\n",
    "        num_leaves=64,\n",
    "        max_depth=10,\n",
    "        learning_rate=0.05,\n",
    "        n_estimators=10000,\n",
    "        subsample=0.8,\n",
    "        feature_fraction=0.8,\n",
    "        reg_alpha=0.5,\n",
    "        reg_lambda=0.5,\n",
    "        random_state=seed,\n",
    "        importance_type='gain',\n",
    "        metric=None,\n",
    "        device_type='gpu',\n",
    "        gpu_device_id=0,\n",
    "        gpu_use_dp=True,\n",
    "        boost_from_average=True\n",
    "    )\n",
    "    \n",
    "    oof = []\n",
    "    prediction = df_test[['user_id', 'article_id']]\n",
    "    prediction['pred'] = 0\n",
    "    df_importance_list = []\n",
    "    \n",
    "    kfold = GroupKFold(n_splits=5)\n",
    "    for fold_id, (trn_idx, val_idx) in enumerate(kfold.split(df_train[feature_names], df_train[ycol], df_train['user_id'])):\n",
    "        X_train = df_train.iloc[trn_idx][feature_names]\n",
    "        Y_train = df_train.iloc[trn_idx][ycol]\n",
    "        X_val = df_train.iloc[val_idx][feature_names]\n",
    "        Y_val = df_train.iloc[val_idx][ycol]\n",
    "        \n",
    "        callbacks = [\n",
    "            lgb.log_evaluation(period=100),\n",
    "            lgb.early_stopping(stopping_rounds=100)\n",
    "        ]\n",
    "        \n",
    "        lgb_model = model.fit(\n",
    "            X_train, Y_train,\n",
    "            eval_set=[(X_train, Y_train), (X_val, Y_val)],\n",
    "            eval_names=['train', 'valid'],\n",
    "            eval_metric='auc',\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "        \n",
    "        pred_val = lgb_model.predict_proba(X_val, num_iteration=lgb_model.best_iteration_)[:, 1]\n",
    "        df_oof = df_train.iloc[val_idx][['user_id', 'article_id', ycol]].copy()\n",
    "        df_oof['pred'] = pred_val\n",
    "        oof.append(df_oof)\n",
    "        \n",
    "        pred_test = lgb_model.predict_proba(df_test[feature_names], num_iteration=lgb_model.best_iteration_)[:, 1]\n",
    "        prediction['pred'] += pred_test / 5\n",
    "        \n",
    "        df_importance = pd.DataFrame({\n",
    "            'feature_name': feature_names,\n",
    "            'importance': lgb_model.feature_importances_,\n",
    "        })\n",
    "        df_importance_list.append(df_importance)\n",
    "        \n",
    "        joblib.dump(model, f'../user_data/model/lgb{fold_id}.pkl')\n",
    "    \n",
    "    return prediction, oof, df_importance_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: 定义在线预测函数\n",
    "def online_predict(df_test):\n",
    "    ycol = 'label'\n",
    "    feature_names = list(filter(lambda x: x not in [ycol, 'created_at_datetime', 'click_datetime'], df_test.columns))\n",
    "    feature_names.sort()\n",
    "    \n",
    "    prediction = df_test[['user_id', 'article_id']]\n",
    "    prediction['pred'] = 0\n",
    "    \n",
    "    for fold_id in tqdm(range(5)):\n",
    "        model = joblib.load(f'../user_data/model/lgb{fold_id}.pkl')\n",
    "        pred_test = model.predict_proba(df_test[feature_names])[:, 1]\n",
    "        prediction['pred'] += pred_test / 5\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: 数据加载与预处理\n",
    "def load_and_process_data(mode='valid'):\n",
    "    if mode == 'valid':\n",
    "        df_feature = pd.read_pickle('../user_data/data/offline/feature.pkl')\n",
    "        df_query = pd.read_pickle('../user_data/data/offline/query.pkl')\n",
    "        \n",
    "        for f in df_feature.select_dtypes('object').columns:\n",
    "            lbl = LabelEncoder()\n",
    "            df_feature[f] = lbl.fit_transform(df_feature[f].astype(str))\n",
    "            \n",
    "        prediction, oof, importance_list = train_model(df_feature, df_query)\n",
    "        return prediction, oof, importance_list, df_query\n",
    "    else:\n",
    "        df_feature = pd.read_pickle('../user_data/data/online/feature.pkl')\n",
    "        prediction = online_predict(df_feature)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: 生成提交文件(可单独运行)\n",
    "def generate_submission(prediction):\n",
    "    df_sub = gen_sub(prediction)\n",
    "    df_sub.sort_values(['user_id'], inplace=True)\n",
    "    os.makedirs('../prediction_result', exist_ok=True)\n",
    "    df_sub.to_csv('../prediction_result/result.csv', index=False)\n",
    "    return df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../user_data/data/offline/feature.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_978832/2182754996.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Cell 7: 执行主流程\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'valid'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moof\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimportance_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m# 评估指标计算\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdf_oof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_978832/3591666542.py\u001b[0m in \u001b[0;36mload_and_process_data\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_and_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'valid'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mdf_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../user_data/data/offline/feature.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mdf_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../user_data/data/offline/query.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tianchi/lib/python3.7/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(path, compression)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \"\"\"\n\u001b[1;32m    144\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_stringify_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;31m# 1) try standard libary Pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tianchi/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../user_data/data/offline/feature.pkl'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cell 7: 执行主流程\n",
    "if mode == 'valid':\n",
    "    prediction, oof, importance_list, df_query = load_and_process_data(mode='valid')\n",
    "    # 评估指标计算\n",
    "    df_oof = pd.concat(oof)\n",
    "    total = df_query[df_query['click_article_id'] != -1].user_id.nunique()\n",
    "    metrics = evaluate(df_oof, total)\n",
    "    print(\"评估指标:\", metrics)\n",
    "else:\n",
    "    prediction = load_and_process_data(mode='online')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [03:45<00:00, 222.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>article_1</th>\n",
       "      <th>article_2</th>\n",
       "      <th>article_3</th>\n",
       "      <th>article_4</th>\n",
       "      <th>article_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>200000</td>\n",
       "      <td>194935</td>\n",
       "      <td>336221</td>\n",
       "      <td>195087</td>\n",
       "      <td>195645</td>\n",
       "      <td>59681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>200001</td>\n",
       "      <td>272143</td>\n",
       "      <td>64329</td>\n",
       "      <td>199198</td>\n",
       "      <td>324823</td>\n",
       "      <td>166581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>200002</td>\n",
       "      <td>202701</td>\n",
       "      <td>208596</td>\n",
       "      <td>205982</td>\n",
       "      <td>203288</td>\n",
       "      <td>206711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>200003</td>\n",
       "      <td>277107</td>\n",
       "      <td>158772</td>\n",
       "      <td>235105</td>\n",
       "      <td>50494</td>\n",
       "      <td>156807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>200004</td>\n",
       "      <td>218028</td>\n",
       "      <td>289003</td>\n",
       "      <td>157478</td>\n",
       "      <td>57966</td>\n",
       "      <td>202355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  article_1  article_2  article_3  article_4  article_5\n",
       "49999   200000     194935     336221     195087     195645      59681\n",
       "49998   200001     272143      64329     199198     324823     166581\n",
       "49997   200002     202701     208596     205982     203288     206711\n",
       "49996   200003     277107     158772     235105      50494     156807\n",
       "49995   200004     218028     289003     157478      57966     202355"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 8: 生成提交文件(按需运行)\n",
    "df_submission = generate_submission(prediction)\n",
    "df_submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
